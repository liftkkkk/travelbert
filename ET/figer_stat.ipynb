{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('python3.6_cuda10.2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6e079afab4c4c4c65d4b43dd91ca61c10d1e8795b4c1eb1f1b89d495966c49f7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "source": [
    "## FIGER dataset explore"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data1/lzh/data/ernie_data/FIGER\"\n",
    "train_file = os.path.join(data_dir, \"train.json\")\n",
    "dev_file = os.path.join(data_dir, \"dev.json\")\n",
    "test_file = os.path.join(data_dir, \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_stat(file_name):\n",
    "    print(f\"dataset file: {file_name}\")\n",
    "    with open(file_name, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    #sentences\n",
    "    print(f\"#sentences: {len(data)}\")\n",
    "\n",
    "    #labels (entity types)\n",
    "    labels = set()\n",
    "    for example in data:\n",
    "        labels.update(example[\"labels\"])\n",
    "    print(f\"#labels (entity types): {len(labels)}\")\n",
    "\n",
    "    # check if all parent classes are in labels\n",
    "    no_parent_examples = 0\n",
    "    for example in data:\n",
    "        labels = example[\"labels\"]\n",
    "        for label in labels:\n",
    "            level = label[1:].split(\"/\")\n",
    "            if len(level) > 1 and \"/\" + level[0] not in labels:\n",
    "                no_parent_examples += 1\n",
    "                break\n",
    "    print(f\"#examples that not all parent classes are in labels: {no_parent_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset file: /data1/lzh/data/ernie_data/FIGER/train.json\n",
      "#sentences: 2000000\n",
      "#labels (entity types): 113\n",
      "#examples that not all parent classes are in labels: 0\n"
     ]
    }
   ],
   "source": [
    "split_stat(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "90 238.0\n",
      "91 241.0\n",
      "92 245.0\n",
      "93 249.0\n",
      "94 253.0\n",
      "95 257.0\n",
      "96 262.0\n",
      "97 268.0\n",
      "98 276.0\n",
      "99 287.0\n",
      "100 951.0\n"
     ]
    }
   ],
   "source": [
    "with open(train_file, \"r\") as file:\n",
    "    train_data = json.load(file)\n",
    "with open(test_file, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "# sentence length distribution\n",
    "sent_lens = np.array([len(example[\"sent\"]) for example in train_data])\n",
    "for i in range(90, 101):\n",
    "    print(i, np.percentile(sent_lens, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#train_entities: 592396\n",
      "#test_entities: 331\n",
      "#overlap entities: 137\n",
      "ratio of examples with > 1 types in train data: 0.7572125\n",
      "ratio of examples with > 1 types in test data: 0.325044404973357\n"
     ]
    }
   ],
   "source": [
    "# entity overlap between train set and test set\n",
    "train_entities = set(example[\"sent\"][example[\"start\"] : example[\"end\"]] for example in train_data)\n",
    "test_entities = set(example[\"sent\"][example[\"start\"] : example[\"end\"]] for example in test_data)\n",
    "\n",
    "print(f\"#train_entities: {len(train_entities)}\")\n",
    "print(f\"#test_entities: {len(test_entities)}\")\n",
    "print(f\"#overlap entities: {len(train_entities & test_entities)}\")\n",
    "\n",
    "n_fine_grained = sum(1 if len(example[\"labels\"]) > 1 else 0 for example in train_data)\n",
    "print(f\"ratio of examples with > 1 types in train data: {n_fine_grained / len(train_data)}\")\n",
    "n_fine_grained = sum(1 if len(example[\"labels\"]) > 1 else 0 for example in test_data)\n",
    "print(f\"ratio of examples with > 1 types in test data: {n_fine_grained / len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset file: /data1/lzh/data/ernie_data/FIGER/dev.json\n#sentences: 10000\n#labels (entity types): 113\n#examples that not all parent classes are in labels: 0\n"
     ]
    }
   ],
   "source": [
    "split_stat(dev_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset file: /data1/lzh/data/ernie_data/FIGER/test.json\n#sentences: 563\n#labels (entity types): 41\n#examples that not all parent classes are in labels: 50\n"
     ]
    }
   ],
   "source": [
    "split_stat(test_file)"
   ]
  },
  {
   "source": [
    "## Convert BIO NER data to FET data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traval_ner_dir = \"/data1/lzh/exp/pretrain/tourism-transformers/utils/tner\"\n",
    "train_file = os.path.join(traval_ner_dir, \"bio.txtl.train\")\n",
    "dev_file = os.path.join(traval_ner_dir, \"bio.txtl.dev\")\n",
    "test_file = os.path.join(traval_ner_dir, \"bio.txtl.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#typing examples: 4693\n#entities: 2488\n#labels: 6 {'建筑', '人物', '文物', '门店', '组织机构', '景点'}\n"
     ]
    }
   ],
   "source": [
    "data = \"\"\n",
    "for file_name in [train_file, dev_file, test_file]:\n",
    "    with open(file_name, \"r\") as file:\n",
    "        data += \"\\n\\n\" + file.read()\n",
    "\n",
    "examples = data.strip().split(\"\\n\\n\")\n",
    "typing_examples = []\n",
    "for example in examples:\n",
    "    chars_with_bio = example.split(\"\\n\")\n",
    "    sentence, spans = [], []\n",
    "    label, start, end = None, -1, -1\n",
    "    for idx, entry in enumerate(chars_with_bio):\n",
    "        char, bio = entry.split(\" \")\n",
    "        sentence.append(char)\n",
    "\n",
    "        assert bio[0] in \"BIO\"\n",
    "        if bio[0] == \"B\":\n",
    "            label = bio[2:]\n",
    "            start, end = idx, idx\n",
    "        elif bio[0] == \"I\":\n",
    "            end = idx\n",
    "        elif start != -1 and end != -1:\n",
    "            spans.append([label, start, end + 1])\n",
    "            start, end = -1, -1\n",
    "\n",
    "    for label, start, end in spans:\n",
    "        assert all(\"B\" in chars_with_bio[idx] or \"I\" in chars_with_bio[idx] for idx in range(start, end))\n",
    "        typing_examples.append(OrderedDict([\n",
    "            (\"sent\", \"\".join(sentence)),\n",
    "            (\"labels\", [label]),\n",
    "            (\"start\", start),\n",
    "            (\"end\", end)\n",
    "        ]))\n",
    "\n",
    "# dataset statistics\n",
    "print(f\"#typing examples: {len(typing_examples)}\")\n",
    "entities, labels = set(), set()\n",
    "for example in typing_examples:\n",
    "    start, end = example[\"start\"], example[\"end\"]\n",
    "    entities.add(example[\"sent\"][start:end])\n",
    "    labels.update(example[\"labels\"])\n",
    "print(f\"#entities: {len(entities)}\")\n",
    "print(f\"#labels: {len(labels)} {labels}\")\n",
    "\n",
    "# save to dir\n",
    "target_path = \"/data1/lzh/data/tourism-FET/test.json\"\n",
    "with open(target_path, \"w\") as writer:\n",
    "    json.dump(typing_examples, writer, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}